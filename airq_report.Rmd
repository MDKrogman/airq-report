---
title: "airq_report"
author: "Matthew Krogman"
output: pdf_document
font_size: 12pt
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(paletteer)
library(patchwork)

airq <- read_csv('air_quality_health_dataset.csv') %>% 
  separate(date, into = c('year', 'month', 'day'), sep = '-')

airq4 <- airq %>% 
  pivot_longer(cols = 6:11,
               names_to = 'pollutant',
               values_to = 'pollutant_level'
              ) %>% 
  relocate(pollutant, pollutant_level, .after = AQI)
airq4$pollutant <- factor(airq4$pollutant, levels = c('CO', 'SO2', 'O3', 'NO2', 'PM2.5', 'PM10'))
```

# Abstract



# Introduction

As climate change continues to progress, and the population of major urban and industrial centers, more attention has been given to the quality of the air and the danger of breathing polluted air. Although emissions of harmful chemicals in the United States have reduced, thanks to the Clean Air Act, the American Lung Association claims that, as of 2024, 131 million Americans live in areas with unhealthy levels of air pollution.^[“2024 ‘State of the Air’ Report Reveals Most ‘Hazardous’ Air Quality Days in 25 Years.” American Lung Association, Saint Paul, United States. April 24, 2024. https://www.lung.org/media/press-releases/sota-2024.] This still-existent trend of more frequent and longer-lasting wildfires.^[Rickly, P. S et al.: “Emission factors and evolution of SO2 measured from biomass burning in wildfires and agricultural fires”, Atmos. *Chem. Phys., 22, 15603–15620*, https://doi.org/10.5194/acp-22-15603-2022, 2022. 15604.] This environmental trend prompts the necessity to create models so that we may be better prepared to handle worsening air quality in the future. With data on pollutants and certain demographic data, it should be possible to prepare for lockdowns based on air quality and predict the demand on hospital resources in a specific location.

# Data

The data to be used in this report is from a synthetic dataset created for Kaggle by Khushi Yadav, using a license from MIT. It is a time series spanning from the beginning of 2020 to the end of 2021. A large number of quantitative variables are included, such as AQI, industrial activity, and measures of the "six common pollutants" ($PM_{2.5}$, $PM_{10}$, $O_{3}$, $CO$, $SO_{2}$, and $NO_{2}$). Qualitative variables like the region and whether or not a lockdown has been issued are also included. Throughout this report, all variables in the dataset will be used in multiple contexts to create effective prediction models for future use.

Though the data may be synthetic, the results are still true to the real world–it was generated using public domain resources on realistic statistical distributions for accuracy, while protecting privacy by limiting real-world attachment to individual data points.

# The Appeal and Drawbacks of GLMs

The state of the data provides a good opportunity to consider using generalized linear models: the response varaibles we are interested in lockdown state (binary) and hospital bed demand (count) violate the assumptions of standard linear modeling. Creating a GLM is simple, but they are easy to overfit. A somewhat explanatory model for lockdown conditions is as follows:

Y ~indep. Bernoulli(p)\newline
$log(\frac{p}{1-p}) = -2.085 -0.017PM_{2.5} - 0.043SO_2 + 2.732CO + 0.002(PM_{2.5} * SO_2) - 0.021(PM_{2.5} * CO) - 0.082(SO_2 * CO)$\newline

$SE_{PM_{2.5}} = 0.02, p = .38$\newline
$SE_{SO_2} = 0.057, p = .45$\newline
$SE_{CO} = 0.953, p = .004$\newline
$SE_{PM_{2.5} * SO_2} = 0.001, p = .006$\newline
$SE_{PM_{2.5} * CO} = 0.011, p = .07$\newline
$SE_{SO_2 * CO} = 0.035, p = .02$\newline

There is quite a bit of doubt to be cast on this model, but it does also pique interest for further consideration. Indeed, there are a number of terms that provide strong evidence for an effect on lockdown status $(p < .05)$. Of note is the interaction term between $PM_{2.5}$ and $SO_{2}$. This can be directly related to environmental factors, like wildfires. Wildfire smoke releases large amounts of $PM_{2.5}$, which in turn contains sulfate $(SO_4)$,^[Ricky et al. 15604.] which can become sulfur dioxide under circumstances like wildfire. 

The possibility of an interaction certainly seems possible based on previous research, but it is possible to see this with a plot that puts this problem in the context of our data scenario. See below:

```{r echo=FALSE, message=FALSE, fig.height=4, fig.width=5, fig.align='center'}
p1 <- ggplot(airq4, aes(x = pollutant_level, y = lockdown_status, color = pollutant)) +
  geom_jitter(height = .4, alpha = .4) + 
  scale_y_continuous(breaks = c(0, 1)) +
  theme_minimal() +
  scale_colour_paletteer_d("MetBrewer::Juarez") +
  theme(
    legend.position = 'none'
  ) +
  labs(
    x = '', y = 'Lockdown Status',
    color = 'Pollutant'
  )

p2 <- ggplot(airq4, aes(x = pollutant_level, y = school_closures, color = pollutant)) +
  geom_jitter(height = .4, alpha = .4) + 
  scale_y_continuous(breaks = c(0, 1)) +
  theme_minimal() +
  scale_colour_paletteer_d("MetBrewer::Juarez") +
  theme(
    legend.position = 'bottom'
  ) +
  labs(
    x = 'Pollutant Level', y = 'School Closure Status',
    color = 'Pollutant'
  )

p1 / p2
```

The main takeaway from this plot is that in both cases of lockdowns and school closures, the pollutant level remains in the same region along the x-axis, regardless of if the observation was part of a day where there was a lockdown or not. The fact that the regions are the same suggests that there is an interactive effect between one or multiple pollutants that has an affect on air quality, such that a lockdown or school closure would be called. Though we are not interested in school closures as a response varaible for this report, it works with lockdown status to confirm our suspicions about an interaction in the data.

The other response variable we will focus on is the number of hospital beds required in a day, made by combining variables relating to hospital resources. That model is as such:

Y ~Poisson($\lambda$)\newline
$log(Y = y) = 3.519 -0.001PM_{10} + 0.006SO_2 + 0.06CO + 0.001(PM_{10} * SO_2) + 0.0002(PM_{10} * CO) - 0.007(SO_2 * CO)$\newline

$SE_{PM_{10}} = 0.0008, p = .07$\newline
$SE_{SO_2} = 0.003, p = .08$\newline
$SE_{CO} = 0.058, p = .30$\newline
$SE_{PM_{10} * SO_2} = 0.00003, p = .43$\newline
$SE_{PM_{10} * CO} = 0.0005, p = .045$\newline
$SE_{SO_2 * CO} = 0.002, p = .0006$\newline

Much like the previous model, a couple of predictors show strong evidence of nonzero impact on the model. Otherwise, evidence is either weak or nonexistent to suggest that the other predictors have no effect on predicting the demand of hospital resources for a day in our dataset. This is another commonality shared with the first model.

In general, while GLMs conceptually seem to be a promising medium for creating predictive models for lockdown prediction and hospital resource demand, they lose their impact in this scenario where interactions are plausible given the situation. The benefit of easy interpretation in lost in some regard. On top of this, we cut many variables to reduce the danger of overfitting.^[Note that both models above only contain three of the six common pollutants. Three were cut for each in process of making both of the above models as they showed no evidence that their coefficients were nonzero.] Now we must turn to other methods of modeling to make up for the drawbacks of GLMs, while also hopefully creating a more accurate model as well.

# Introducing Machine Learning Models for Predictive Use

We have many concerns when trying to fit a GLM to this data. Thankfully, many of the concerns, like overfitting, can be addressed by building machine learning models using random forest. What is lost in terms of interperatability is regained in terms of accuracy. Using the tidymodels meta-package in R, this process is quite efficient.^[Version 1.3.0 of the tidymodels meta-package used within R version 4.4.2 "Pile of Leaves".]

When making these machine learning models, it is feasable to fit all of the varaibles without fear of overfitting and overtraining the model. This also enables us to achieve high levels of accuracy in predicting outcomes in our variables of interest (lockdown status and demand on hospital resources).

The first model, about lockdown status, first novelizes and creates dummy variables for the nominal predictors (month, region). Areas of zero variance are removed, then the numeric variables are all normalized. Lastly, an interaction step is added with all of the "six common pollutants" to make full use of their potential interactions without worrying about overfitting. Training the model recipe through tidymodels' workflow map system, we are also able to use hyperparameters to their highest function (mtry = 25, min_n = 35) to increase model performance further. What results is a ML model that is able to predict with 85.7% accuracy whether or not there is a lockdown on a random day when testing data is introduced.

The second model focuses on the demand of hospital resources, again drawing that number from multiple variables related to hospital resources. This is another randomforest model which creates dummy variables for the nominal predictors, normalizes numeric predictors, and uses the same interaction terms as the previous model. The hyperparameters mtry and min_n are again in use, and they are set to 1 and 14, respectively-this setup resulted in the lowest rmse across all models (5.92). This number seems somewhat high on first inspection, but when considering the practical use of a model like this with data that only has one observation per day, it is much more acceptable. The model can be used to give guidence to hospitals and clinics on how many patients they would come to expect on a singular day. Resources can then be allocated based on its predictions. Since hospitals admit patients throughout the day, rather than all at once, the seemingly large rmse is less of a worry.

# Discussion


